{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe: Bringe einer KI bei eine Rakete zu landen\n",
    "Wir nutzen das `LunarLander` environment aus der `gymnasium` Bibliothek, um ein weiteres klassisches Kontrollproblem zu lösen: Eine Rakete in einem Ziel zu landen und dabei möglichst einfach zu sein. Dabei vereinfachen wir das Problem und nehmen diskrete Aktionen an. In jedem Zeitschritt kann die Rakete entweder alle Triebwerke ausschalten, das Haupttriebwerk einschalten, das linke Steuertriebwerk einschalten oder das rechte Steuertriebwerk einschalten. Diese Annahme ist aber okay, [Pontryagin’s maximum principle](https://en.wikipedia.org/wiki/Pontryagin%27s_maximum_principle) gilt.\n",
    "\n",
    "Unser reward wird wie folgt berechnet:\n",
    "- größer wenn näher an Zielzone\n",
    "- größer wenn langsamer\n",
    "- kleiner wenn nicht gerade ausgerichtet\n",
    "- +10 Punkte für jedes Bein auf dem Boden\n",
    "- -0.03 Punkte für jeden Zeitschritt in dem ein Steuertriebwerk verwendet wird\n",
    "- -0.3 Punkte für jeden Zeitschritt in dem das Haupttriebwerk verwendet wird\n",
    "- -100 Punkte für umfallen\n",
    "- +100 Punkte für jede Landung\n",
    "\n",
    "Das Problem gilt als gelöst, wenn 200 Punkte erzielt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (0.28.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from gymnasium) (2.2.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from gymnasium) (1.23.5)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from gymnasium) (4.5.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: jax-jumpy>=1.0.0 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from gymnasium) (1.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: Invalid requirement: '#'\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (2.12.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.54.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.5.9)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.3)\n",
      "Requirement already satisfied: setuptools in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (65.5.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (16.0.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.10)\n",
      "Requirement already satisfied: packaging in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.23.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: scipy>=1.7 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.10.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.30.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.3.4)\n",
      "Requirement already satisfied: urllib3<2.0 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.15)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\ingenieruswissenschaftliches kolleg\\qanda\\reinforcement learning\\venv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install gymnasium\n",
    "! pip install -U gymnasium[box2d]  # Achtung MS Visual C++ Build tools müssen installiert sein: https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
    "! pip install -U tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "env = gym.make(\"LunarLander-v2\",\n",
    "                continuous=False,       # we chose discrete actions (engine on/off)\n",
    "                gravity=-9.81,          # value between 0 and -12, here earth-like gravity\n",
    "                enable_wind=False,      # for now we have no wind but we could turn it on\n",
    "                wind_power=15.0,        # only relevant if wind is active\n",
    "                turbulence_power=1.5,   # only relevent if wind is active\n",
    "                render_mode=\"human\")\n",
    "obs, info = env.reset()  # Start Simulation\n",
    "\n",
    "for _ in range(1000):\n",
    "    action = env.action_space.sample()  # Choose random action\n",
    "    obs, reward, terminated, truncated, info = env.step(action)  # perform random action in simulation\n",
    "\n",
    "    # if our agent fails we reset the environment\n",
    "    if terminated or truncated:\n",
    "        obs, info = env.reset()\n",
    "\n",
    "env.close()  # start the rendering for us to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space Discrete(4)\n",
      "Action space size: 4\n",
      "Observation space shape: (8,)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "env = gym.make(\"LunarLander-v2\",\n",
    "                continuous=False,       # we chose discrete actions (engine on/off)\n",
    "                gravity=-9.81,          # value between 0 and -12, here earth-like gravity\n",
    "                enable_wind=False,      # for now we have no wind but we could turn it on\n",
    "                wind_power=15.0,        # only relevant if wind is active\n",
    "                turbulence_power=1.5    # only relevent if wind is active\n",
    "                )\n",
    "\n",
    "print(f'Action space {env.action_space}')\n",
    "print(f'Action space size: {env.action_space.n}')\n",
    "\n",
    "obs = env.reset()\n",
    "\n",
    "print(f'Observation space shape: {obs[0].shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir sehen, wir können aus vier Aktionen wählen, diese sind wie folgt gemappt:\n",
    "- 0: nichts tun\n",
    "- 1: linkes Steuertriebwerk feuern\n",
    "- 2: Haupttriebwerk feuer\n",
    "- 3: rechtes Steuertriebwerk feuern\n",
    "\n",
    "Außerdem erhalten wir einen 8-dimensionalen Vektor als Observation. Dieses beinhaltet:\n",
    "- x-Koordinate des Landers\n",
    "- y-Koordniate des Landers\n",
    "- x-Geschwindigkeit des Landers\n",
    "- y-Geschwindigkeit des Landers\n",
    "- Ausrichtungswinkel (Abweichung von vertikal) des Landers\n",
    "- boolean der Kontakt des linken Beins mit Boden anzeigt\n",
    "- boolean der Kontakt des rechten Beins mit Boden anzeigt\n",
    "\n",
    "Basierend auf diesen Informationen kann eine KI lernen den Lander sicher zum Ziel zu bringen.\n",
    "\n",
    "## Implementtierung\n",
    "**Hier soll eure Implementierung des Double-Deep-Q-Learning Algorithmuses folgen...**\n",
    "\n",
    "Orientiert euch dabei gerne an der Implementierung für die Lösung des CartPole Problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
